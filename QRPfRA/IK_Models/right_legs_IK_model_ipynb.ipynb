{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from gymnasium import utils\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium.error import Error\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QRPfRA_v3(MujocoEnv, utils.EzPickle):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, xml_file=\"/Users/deniz/PycharmProjects/QRPfRA_Senior_Project/QRPfRA/IK_Models/qrpfra_v3_leg_ik_scene_right.xml\", frame_skip=1, **kwargs):\n",
    "        utils.EzPickle.__init__(self, xml_file, frame_skip, **kwargs)\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self,\n",
    "            xml_file,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=None,  # needs to be defined after\n",
    "            default_camera_config={},\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "        obs_size = self.data.qpos.size + self.data.qvel.size\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, shape=(obs_size,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "\n",
    "        self.do_simulation(action, self.frame_skip)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        reward = 0\n",
    "        info = {}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        return observation, reward, False, False, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        sensor_data = self.data.sensordata.flat.copy()\n",
    "\n",
    "        return sensor_data\n",
    "\n",
    "    def reset_model(self):\n",
    "        qpos = self.init_qpos\n",
    "        qvel = self.init_qvel\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _get_reset_info(self):\n",
    "        return {\"works\": True}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([ 0.046 ,  0.1435, -0.1245,  0.    ,  0.    ,  0.    ]), {'works': True})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:247: UserWarning: \u001b[33mWARN: For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:225: UserWarning: \u001b[33mWARN: A Box observation space minimum value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:229: UserWarning: \u001b[33mWARN: A Box observation space maximum value is -infinity. This is probably too high.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:321: UserWarning: \u001b[33mWARN: Not able to test alternative render modes due to the environment not having a spec. Try instantialising the environment through gymnasium.make\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = QRPfRA_v3()\n",
    "check_env(env)\n",
    "obs = env.reset()\n",
    "print(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "leg_dataset = [] # [obs0, obs1, obs2, act0, act1, act2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-100, 101, 4):\n",
    "    for j in range(-100, 101, 4):\n",
    "        for k in range(-100, 101, 4):\n",
    "            #env.render_mode = \"human\"\n",
    "            env_obs = []\n",
    "            for step_cnt in range(0,3):\n",
    "                obs, reward, done, _, info = env.step([float(m) for m in [i, j, k]])\n",
    "                if step_cnt == 2:\n",
    "                    env_obs = obs\n",
    "            \n",
    "\n",
    "            leg_dataset.append([env_obs[0], env_obs[1], env_obs[2], i/100, j/100, k/100])\n",
    "\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "132651\n"
     ]
    }
   ],
   "source": [
    "print(len(leg_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the leg_dataset variable to a text file with comma separation\n",
    "np.savetxt('leg_dataset.txt', leg_dataset, delimiter=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert left leg list to numpy array\n",
    "leg_dataset_as_np = np.array(leg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.16802824 -0.17832992 -0.02959151 -1.         -1.         -1.        ]\n",
      " [ 0.18593527 -0.15028785 -0.05653176 -1.         -1.         -0.96      ]\n",
      " [ 0.18776632 -0.1465833  -0.05628311 -1.         -1.         -0.92      ]\n",
      " [ 0.190028   -0.14132874 -0.05799825 -1.         -1.         -0.88      ]]\n",
      "[[1.16802824 0.82167008 0.97040849]\n",
      " [1.18593527 0.84971215 0.94346824]\n",
      " [1.18776632 0.8534167  0.94371689]\n",
      " ...\n",
      " [1.08074731 1.04767694 0.99132841]\n",
      " [1.07875458 1.04270491 0.99018395]\n",
      " [1.07659415 1.03785968 0.98894317]]\n",
      "[[-1.   -1.   -1.  ]\n",
      " [-1.   -1.   -0.96]\n",
      " [-1.   -1.   -0.92]\n",
      " ...\n",
      " [ 1.    1.    0.92]\n",
      " [ 1.    1.    0.96]\n",
      " [ 1.    1.    1.  ]]\n"
     ]
    }
   ],
   "source": [
    "print(leg_dataset_as_np[0:4])\n",
    "\n",
    "observations = (leg_dataset_as_np[:, 0:3][:] + 1)\n",
    "print(observations)\n",
    "actions = leg_dataset_as_np[:, 3:][:]\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "66326/66326 [==============================] - 79s 1ms/step - loss: 0.1532 - accuracy: 0.5384\n",
      "Epoch 2/10\n",
      "66326/66326 [==============================] - 79s 1ms/step - loss: 0.0983 - accuracy: 0.6474\n",
      "Epoch 3/10\n",
      "66326/66326 [==============================] - 72s 1ms/step - loss: 0.0855 - accuracy: 0.7195\n",
      "Epoch 4/10\n",
      "66326/66326 [==============================] - 82s 1ms/step - loss: 0.0641 - accuracy: 0.8046\n",
      "Epoch 5/10\n",
      "66326/66326 [==============================] - 82s 1ms/step - loss: 0.0523 - accuracy: 0.8441\n",
      "Epoch 6/10\n",
      "66326/66326 [==============================] - 86s 1ms/step - loss: 0.0459 - accuracy: 0.8642\n",
      "Epoch 7/10\n",
      "66326/66326 [==============================] - 87s 1ms/step - loss: 0.0418 - accuracy: 0.8718\n",
      "Epoch 8/10\n",
      "66326/66326 [==============================] - 84s 1ms/step - loss: 0.0390 - accuracy: 0.8777\n",
      "Epoch 9/10\n",
      "66326/66326 [==============================] - 86s 1ms/step - loss: 0.0367 - accuracy: 0.8814\n",
      "Epoch 10/10\n",
      "66326/66326 [==============================] - 73s 1ms/step - loss: 0.0350 - accuracy: 0.8844\n",
      "415/415 [==============================] - 0s 625us/step - loss: 0.0334 - accuracy: 0.8961\n",
      "Test Loss: [0.03344761207699776, 0.8960500359535217]\n",
      "Current Time: 2024-02-29 20:57:24.480631\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "import datetime\n",
    "from tensorflow.keras import layers, models\n",
    "\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_obs, test_obs, train_actions, test_actions = train_test_split(observations, actions, test_size=0.1, shuffle=True)\n",
    "\n",
    "# Define the model architecture\n",
    "\n",
    "ik_input = tf.keras.Input(shape=(3,))\n",
    "x = layers.Dense(128, activation=\"relu\")(ik_input)\n",
    "x = layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2())(x)\n",
    "x = layers.Dense(128, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2())(x)\n",
    "\n",
    "ik_output = layers.Dense(3, activation=\"tanh\")(x)\n",
    "\n",
    "\n",
    "model = models.Model(ik_input, ik_output)\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.legacy.Adam(learning_rate=0.0001)  # Set the learning rate here\n",
    "model.compile(optimizer=optimizer, loss=tf.keras.losses.Huber(), metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(observations, actions, epochs=10, batch_size=2)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss = model.evaluate(test_obs, test_actions)\n",
    "print('Test Loss:', test_loss)\n",
    "current_time = datetime.datetime.now()\n",
    "print(\"Current Time:\", current_time)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: right_legs_model_plus50/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: right_legs_model_plus50/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"right_legs_model_plus50\", overwrite=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QRPfRA_Senior_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pytest\n",
    "\n",
    "from gymnasium import utils\n",
    "from gymnasium.envs.mujoco import MujocoEnv\n",
    "from gymnasium.error import Error\n",
    "from gymnasium.spaces import Box\n",
    "from gymnasium.utils.env_checker import check_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QRPfRA_v3(MujocoEnv, utils.EzPickle):\n",
    "    metadata = {\n",
    "        \"render_modes\": [\n",
    "            \"human\",\n",
    "            \"rgb_array\",\n",
    "            \"depth_array\",\n",
    "        ],\n",
    "    }\n",
    "\n",
    "    def __init__(self, xml_file=\"/Users/deniz/PycharmProjects/QRPfRA_Senior_Project/QRPfRA_sim_body_STLs/qrpfra_v3_leg_ik_scene.xml\", frame_skip=1, **kwargs):\n",
    "        utils.EzPickle.__init__(self, xml_file, frame_skip, **kwargs)\n",
    "\n",
    "        MujocoEnv.__init__(\n",
    "            self,\n",
    "            xml_file,\n",
    "            frame_skip=frame_skip,\n",
    "            observation_space=None,  # needs to be defined after\n",
    "            default_camera_config={},\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "        self.metadata = {\n",
    "            \"render_modes\": [\n",
    "                \"human\",\n",
    "                \"rgb_array\",\n",
    "                \"depth_array\",\n",
    "            ],\n",
    "            \"render_fps\": int(np.round(1.0 / self.dt)),\n",
    "        }\n",
    "\n",
    "        obs_size = self.data.qpos.size + self.data.qvel.size\n",
    "\n",
    "        self.observation_space = Box(\n",
    "            low=-np.inf, high=np.inf, shape=(obs_size,), dtype=np.float64\n",
    "        )\n",
    "\n",
    "    def step(self, action):\n",
    "        x_position_before = self.data.qpos[0]\n",
    "\n",
    "        self.do_simulation(action, self.frame_skip)\n",
    "        x_position_after = self.data.qpos[0]\n",
    "\n",
    "        observation = self._get_obs()\n",
    "        reward = x_position_after - x_position_before\n",
    "        info = {}\n",
    "\n",
    "        if self.render_mode == \"human\":\n",
    "            self.render()\n",
    "\n",
    "        return observation, reward, False, False, info\n",
    "\n",
    "    def _get_obs(self):\n",
    "        #position = self.data.qpos.flat.copy()\n",
    "        #velocity = self.data.qvel.flat.copy()\n",
    "        sensor_data = self.data.sensordata.flat.copy()\n",
    "\n",
    "        return sensor_data\n",
    "\n",
    "    def reset_model(self):\n",
    "        qpos = self.init_qpos\n",
    "        qvel = self.init_qvel\n",
    "        self.set_state(qpos, qvel)\n",
    "\n",
    "        observation = self._get_obs()\n",
    "\n",
    "        return observation\n",
    "\n",
    "    def _get_reset_info(self):\n",
    "        return {\"works\": True}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([-0.045 ,  0.1335, -0.107 ,  0.    ,  0.    ,  0.    ]), {'works': True})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:247: UserWarning: \u001b[33mWARN: For Box action spaces, we recommend using a symmetric and normalized space (range=[-1, 1] or [0, 1]). See https://stable-baselines3.readthedocs.io/en/master/guide/rl_tips.html for more information.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:225: UserWarning: \u001b[33mWARN: A Box observation space minimum value is -infinity. This is probably too low.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:229: UserWarning: \u001b[33mWARN: A Box observation space maximum value is -infinity. This is probably too high.\u001b[0m\n",
      "  logger.warn(\n",
      "/Users/deniz/miniconda3/envs/QRPfRA_Senior_Project/lib/python3.11/site-packages/gymnasium/utils/env_checker.py:321: UserWarning: \u001b[33mWARN: Not able to test alternative render modes due to the environment not having a spec. Try instantialising the environment through gymnasium.make\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = QRPfRA_v3()\n",
    "check_env(env)\n",
    "obs = env.reset()\n",
    "print(obs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "left_leg_dataset = [] # [obs0, obs1, obs2, act0, act1, act2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(-100, 100):\n",
    "    for j in range(-100, 100):\n",
    "        for k in range(-100, 100):\n",
    "            #env.render_mode = \"human\"\n",
    "\n",
    "            obs, reward, done, _, info = env.step([float(m) for m in [i, j, k]])\n",
    "            left_leg_dataset.append([obs[0], obs[1], obs[2], i/100, j/100, k/100])\n",
    "\n",
    "            #print(obs)\n",
    "            if done:\n",
    "                env.reset()\n",
    "\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8238193\n"
     ]
    }
   ],
   "source": [
    "print(len(left_leg_dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert left leg list to numpy array\n",
    "left_leg_dataset_as_np = np.array(left_leg_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.045       0.1335     -0.107      -1.         -1.         -1.        ]\n",
      " [ 0.00872301  0.08305386 -0.17710357 -1.         -1.         -0.99      ]\n",
      " [ 0.10444321 -0.03413705 -0.18731909 -1.         -1.         -0.98      ]\n",
      " [ 0.13397228 -0.11299516 -0.14351767 -1.         -1.         -0.97      ]]\n",
      "[[-0.045       0.1335     -0.107     ]\n",
      " [ 0.00872301  0.08305386 -0.17710357]\n",
      " [ 0.10444321 -0.03413705 -0.18731909]\n",
      " ...\n",
      " [ 0.02371278  0.04512389  0.07646926]\n",
      " [ 0.02321392  0.04400059  0.07617783]\n",
      " [ 0.02270487  0.04288343  0.07588045]]\n",
      "[[-1.   -1.   -1.  ]\n",
      " [-1.   -1.   -0.99]\n",
      " [-1.   -1.   -0.98]\n",
      " ...\n",
      " [ 0.99  0.99  0.97]\n",
      " [ 0.99  0.99  0.98]\n",
      " [ 0.99  0.99  0.99]]\n"
     ]
    }
   ],
   "source": [
    "print(left_leg_dataset_as_np[0:4])\n",
    "\n",
    "observations = left_leg_dataset_as_np[:, 0:3][:]\n",
    "print(observations)\n",
    "actions = left_leg_dataset_as_np[:, 3:][:]\n",
    "print(actions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "231700/231700 [==============================] - 119s 513us/step - loss: 0.0274 - accuracy: 0.9151\n",
      "Epoch 2/3\n",
      "231700/231700 [==============================] - 121s 524us/step - loss: 0.0237 - accuracy: 0.9258\n",
      "Epoch 3/3\n",
      "231700/231700 [==============================] - 118s 511us/step - loss: 0.0230 - accuracy: 0.9277\n",
      "25745/25745 [==============================] - 9s 344us/step - loss: 0.0221 - accuracy: 0.9364\n",
      "Test Loss: [0.022083459421992302, 0.9363526105880737]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_obs, test_obs, train_actions, test_actions = train_test_split(observations, actions, test_size=0.1)\n",
    "\n",
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(3, activation='relu', input_shape=(3,)),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(3, activation='tanh')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(train_obs, train_actions, epochs=3, batch_size=32)\n",
    "\n",
    "# Evaluate the model on the testing set\n",
    "test_loss = model.evaluate(test_obs, test_actions)\n",
    "print('Test Loss:', test_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: left_legs_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: left_legs_model/assets\n"
     ]
    }
   ],
   "source": [
    "model.save(\"left_legs_model\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "QRPfRA_Senior_Project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
